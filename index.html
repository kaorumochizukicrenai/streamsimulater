<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Gemini Native Audio Dialog - RealtimeInput Mic → Chat (Single HTML)</title>
  <style>
    :root {
      --bg:#0b0f19; --text:#e7ecff; --muted:#aab3d6; --accent:#7aa2ff;
      --bad:#ff6b6b; --good:#33d69f; --border:rgba(255,255,255,.08); --shadow:rgba(0,0,0,.35);
    }
    *{box-sizing:border-box}
    body{margin:0;font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,"Hiragino Kaku Gothic ProN","Noto Sans JP","Yu Gothic",sans-serif;
      background:radial-gradient(1000px 700px at 20% 0%, #12224d 0%, var(--bg) 55%);color:var(--text)}
    header{padding:18px 16px;border-bottom:1px solid var(--border);background:rgba(10,14,24,.75);backdrop-filter:blur(10px);position:sticky;top:0;z-index:5}
    header h1{margin:0 0 6px;font-size:16px;font-weight:700}
    header .sub{margin:0;font-size:12px;color:var(--muted);line-height:1.4}
    main{padding:16px;display:grid;gap:12px;grid-template-columns:380px 1fr}
    @media (max-width:980px){main{grid-template-columns:1fr}}
    .card{background:linear-gradient(180deg,rgba(255,255,255,.03),rgba(255,255,255,.015));
      border:1px solid var(--border);border-radius:14px;box-shadow:0 10px 25px var(--shadow);overflow:hidden}
    .card .hd{padding:12px 12px 10px;border-bottom:1px solid var(--border);background:rgba(255,255,255,.02);
      display:flex;align-items:center;justify-content:space-between;gap:10px}
    .card .hd .title{font-size:13px;font-weight:700}
    .card .bd{padding:12px}
    label{display:block;font-size:12px;color:var(--muted);margin:10px 0 6px}
    input,textarea{width:100%;padding:10px 10px;border-radius:10px;border:1px solid var(--border);
      background:rgba(10,14,24,.55);color:var(--text);outline:none}
    textarea{min-height:70px;resize:vertical}
    .row{display:grid;grid-template-columns:1fr 1fr;gap:10px}
    @media (max-width:980px){.row{grid-template-columns:1fr}}
    .btns{display:flex;gap:10px;flex-wrap:wrap;margin-top:12px}
    button{border:1px solid var(--border);background:rgba(122,162,255,.15);color:var(--text);
      padding:10px 12px;border-radius:12px;cursor:pointer;font-weight:700}
    button:hover{background:rgba(122,162,255,.22)}
    button:disabled{cursor:not-allowed;opacity:.55}
    .danger{background:rgba(255,107,107,.15)} .danger:hover{background:rgba(255,107,107,.22)}
    .ghost{background:rgba(255,255,255,.04)} .ghost:hover{background:rgba(255,255,255,.06)}
    .status{display:flex;align-items:center;gap:10px;font-size:12px;color:var(--muted)}
    .dot{width:10px;height:10px;border-radius:999px;background:rgba(255,255,255,.18);box-shadow:0 0 0 3px rgba(255,255,255,.04)}
    .dot.good{background:var(--good);box-shadow:0 0 0 3px rgba(51,214,159,.15)}
    .dot.bad{background:var(--bad);box-shadow:0 0 0 3px rgba(255,107,107,.15)}
    .chat{height:calc(100vh - 170px);min-height:520px;overflow:auto;padding:12px;
      background:linear-gradient(180deg,rgba(255,255,255,.02),rgba(255,255,255,.01))}
    .msg{max-width:900px;margin:0 0 10px;padding:10px 12px;border-radius:14px;border:1px solid var(--border);
      background:rgba(16,24,42,.75);box-shadow:0 10px 20px rgba(0,0,0,.18)}
    .msg.you{margin-left:auto;background:rgba(122,162,255,.12)}
    .meta{display:flex;align-items:center;gap:8px;margin-bottom:6px;font-size:11px;color:var(--muted)}
    .role{font-weight:800;color:var(--text)}
    .pill{font-size:10px;padding:2px 8px;border-radius:999px;border:1px solid var(--border);
      background:rgba(255,255,255,.04);color:var(--muted)}
    .text{white-space:pre-wrap;line-height:1.45;font-size:13px}
    .small{font-size:11px;color:var(--muted);line-height:1.35;margin-top:8px}
    .warn{color:rgba(255,217,102,.95)}
  </style>
</head>
<body>
<header>
  <h1>Gemini Native Audio Dialog（音声→AI、AI→チャット表示）テスト</h1>
  <p class="sub">
    修正版：音声は realtimeInput.media_chunks で送る（clientContentに音声を載せない）。VAD無効＋ActivityStart/Endでクール区切り。
  </p>
</header>

<main>
  <section class="card">
    <div class="hd">
      <div class="title">設定 / 操作</div>
      <div class="status"><span class="dot" id="statusDot"></span><span id="statusText">未接続</span></div>
    </div>
    <div class="bd">
      <label>API Key（テスト用・クライアント直置き）</label>
      <input id="apiKey" type="password" placeholder="AIza..." autocomplete="off"/>

      <label>モデル名</label>
      <input id="modelName" type="text" value="models/gemini-2.5-flash-native-audio-preview-12-2025" />

      <div class="row">
        <div>
          <label>1クール秒数（録音→送信）</label>
          <input id="cycleSec" type="number" min="1" max="15" step="1" value="6" />
        </div>
        <div>
          <label>AI音声を再生（任意）</label>
          <input id="playAudio" type="checkbox" />
          <div class="small">OFFでもOK（チャットは outputTranscription で表示）</div>
        </div>
      </div>

      <label>システム指示（任意）</label>
      <textarea id="systemInstruction" placeholder="例：日本語で簡潔。音声が途中で区切れているなら返答を保留して次のクールを待ってよい。">貴方は、私の配信を見ながらコメントをしているリスナーです。あなたは「Aさん」という表示名とし、一人分のみをシミュレートしてほしいです。スマホの入力として送りそうな短い内容で送信してください。記号や絵文字などによる感情の付与も、あったりなかったりランダムで操作してほしいです。またあなたは、私のすべての発言に対してコメントをするとは限らないです。ランダムでわざと返答しなかったり、他のリスナーもいる想定で、先ほどまでとは違う話題も進行するかもしれないことを、あなたと私は認知している前提でお願いします。さらに、文章が途切れている可能性がある場合は、無理に返答しないで良いです。さらにさらに、明らかに私からの返答が的を外れている場合、もしくはランダムで今の話題について、もしくはランダムで突然話題を変えて、あなたから私に疑問や質問を送っても、送らなくても構いません。また、無言の場合はメッセージを送信する必要はありません。さらに、最初は入出していない想定で、入室した場合は「（入室）」と出力してください。一度入室したら退出はしないものと仮定してください。</textarea>

      <div class="btns">
        <button id="btnStart">シミュレート開始</button>
        <button id="btnStop" class="danger" disabled>シミュレート停止</button>
        <button id="btnClear" class="ghost">表示クリア</button>
      </div>

      <p class="small warn">
        ※ 音声は realtimeInput で送信します（仕様上、realtimeInput は連続送信でき、clientContent は会話履歴/テキスト向け）。:contentReference[oaicite:2]{index=2}
        <br>※ VAD無効時は ActivityStart/End を送る必要があります。:contentReference[oaicite:3]{index=3}
      </p>

      <div class="small" id="debugBox"></div>
    </div>
  </section>

  <!--　↓　2026/02/01 18:08 修正　-->
  <!--
  <section class="card">
    <div class="hd">
      <div class="title">チャットログ</div>
      <div class="status">
        <span class="pill" id="turnInfo">turn: 0</span>
        <span class="pill" id="chunkInfo">chunk: 0</span>
      </div>
    </div>
    <div class="chat" id="chat"></div>
  </section>
  -->

  <section class="card">
    <div class="hd">
      <div class="title">AIからの返答（outputTranscription）</div>
      <div class="status">
        <span class="pill" id="turnInfo">turn: 0</span>
      </div>
    </div>
    <div class="chat" id="logAI"></div>
  </section>
  
  <section class="card">
    <div class="hd">
      <div class="title">あなたの発声テキスト（inputTranscription）</div>
      <div class="status">
        <span class="pill" id="chunkInfo">chunk: 0</span>
      </div>
    </div>
    <div class="chat" id="logUser"></div>
  </section>
  
  <section class="card">
    <div class="hd">
      <div class="title">その他ログ（WS / debug / error）</div>
      <div class="status">
        <span class="pill" id="connInfo">conn: -</span>
      </div>
    </div>
    <div class="chat" id="logOther"></div>
  </section>
  <!--　↑　2026/02/01 18:08 修正　-->

</main>

<script>
const WS_BASE =
  "wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent";

const el = (id) => document.getElementById(id);
const ui = {
  apiKey: el("apiKey"),
  modelName: el("modelName"),
  cycleSec: el("cycleSec"),
  playAudio: el("playAudio"),
  systemInstruction: el("systemInstruction"),
  btnStart: el("btnStart"),
  btnStop: el("btnStop"),
  btnClear: el("btnClear"),
  statusDot: el("statusDot"),
  statusText: el("statusText"),
  debugBox: el("debugBox"),
  /*　↓　2026/02/01 18:11　追加　*/
  //chat: el("chat"),
  logAI: el("logAI"),
  logUser: el("logUser"),
  logOther: el("logOther"),
  connInfo: el("connInfo"),
  /*　↑　2026/02/01 18:11　追加　*/
  turnInfo: el("turnInfo"),
  chunkInfo: el("chunkInfo"),
};

let ws = null;

// Audio capture
let audioCtx = null;
let mediaStream = null;
let sourceNode = null;
let workletNode = null;
let keepAliveGain = null;

// Optional playback
let playbackCtx = null;

// State
let running = false;
let cycleTimer = null;
let setupDone = false;

let turnCount = 0;
let chunkCount = 0;

// 1クール分のPCM(16k/16bit)を貯める
let pcmBytesQueue = [];

// UI紐付け（入力転写が来たら追記）
let pendingUserChunks = [];

// AI出力転写（turnCompleteまで蓄積）
let currentAssistantText = "";

// ---------- UI helpers ----------
function setStatus(kind, text) {
  ui.statusText.textContent = text;
  ui.statusDot.classList.remove("good","bad");
  if (kind==="good") ui.statusDot.classList.add("good");
  if (kind==="bad") ui.statusDot.classList.add("bad");
}
function logDebug(html){ ui.debugBox.innerHTML = html; }

/*　↓　2026/02/01 18:11 修正　*/
//function clearChat(){ ui.chat.innerHTML = ""; }
function clearAllLogs() {
  ui.logAI.innerHTML = "";
  ui.logUser.innerHTML = "";
  ui.logOther.innerHTML = "";
}
/*　↑　2026/02/01 18:11 修正　*/

function addMessage(role, text, extraPills=[]){
  const msg=document.createElement("div");
  msg.className="msg " + (role==="you" ? "you":"ai");
  const meta=document.createElement("div"); meta.className="meta";

  const roleEl=document.createElement("span"); roleEl.className="role";
  roleEl.textContent= role==="you"?"YOU":"AI";
  meta.appendChild(roleEl);

  const tsEl=document.createElement("span"); tsEl.className="pill";
  tsEl.textContent=new Date().toLocaleTimeString();
  meta.appendChild(tsEl);

  for(const p of extraPills){
    const pill=document.createElement("span"); pill.className="pill";
    pill.textContent=p; meta.appendChild(pill);
  }

  const body=document.createElement("div"); body.className="text";
  body.textContent=text;

  msg.appendChild(meta); msg.appendChild(body);

  /*　↓　2026/02/01 18:29　追加　*/
  ui.logAI.appendChild(msg);
  ui.logAI.scrollTop=ui.logAI.scrollHeight;
  //ui.chat.appendChild(msg);
  //ui.chat.scrollTop=ui.chat.scrollHeight;
  /*　↑　2026/02/01 18:29　追加　*/
  
  return msg;
}

/*　↓　2026/02/01 18:11　追加　*/
function appendLine(containerEl, label, text, pills = []) {
  const msg = document.createElement("div");
  msg.className = "msg";

  const meta = document.createElement("div");
  meta.className = "meta";

  const roleEl = document.createElement("span");
  roleEl.className = "role";
  roleEl.textContent = label;
  meta.appendChild(roleEl);

  const tsEl = document.createElement("span");
  tsEl.className = "pill";
  tsEl.textContent = new Date().toLocaleTimeString();
  meta.appendChild(tsEl);

  for (const p of pills) {
    const pill = document.createElement("span");
    pill.className = "pill";
    pill.textContent = p;
    meta.appendChild(pill);
  }

  const body = document.createElement("div");
  body.className = "text";
  body.textContent = text;

  msg.appendChild(meta);
  msg.appendChild(body);

  containerEl.appendChild(msg);
  containerEl.scrollTop = containerEl.scrollHeight;

  return msg;
}

function logAI(text, pills=[])    { return appendLine(ui.logAI,   "AI",   text, pills); }
function logUser(text, pills=[])  { return appendLine(ui.logUser, "YOU",  text, pills); }
function logOther(text, pills=[]) { return appendLine(ui.logOther,"LOG",  text, pills); }
/*　↑　2026/02/01 18:11　追加　*/

function updateCounters(){
  ui.turnInfo.textContent = "turn: " + turnCount;
  ui.chunkInfo.textContent = "chunk: " + chunkCount;
}
function resetStateAll(){
  turnCount=0; chunkCount=0;
  pcmBytesQueue=[]; pendingUserChunks=[]; currentAssistantText="";
  setupDone=false;
  updateCounters(); setStatus("","未接続"); logDebug("");
}

// ---------- binary helpers ----------
function concatUint8(arrays){
  const total=arrays.reduce((s,a)=>s+a.length,0);
  const out=new Uint8Array(total);
  let off=0; for(const a of arrays){ out.set(a,off); off+=a.length; }
  return out;
}
function uint8ToBase64(u8){
  const chunk=0x8000; let bin="";
  for(let i=0;i<u8.length;i+=chunk){
    bin += String.fromCharCode.apply(null, u8.subarray(i, i+chunk));
  }
  return btoa(bin);
}
function base64ToUint8(b64){
  const bin=atob(b64);
  const out=new Uint8Array(bin.length);
  for(let i=0;i<bin.length;i++) out[i]=bin.charCodeAt(i);
  return out;
}

// ---------- audio conversion ----------
function floatToPCM16Bytes(float32){
  const buf=new ArrayBuffer(float32.length*2);
  const view=new DataView(buf);
  for(let i=0;i<float32.length;i++){
    let s=Math.max(-1,Math.min(1,float32[i]));
    view.setInt16(i*2, s<0 ? s*0x8000 : s*0x7fff, true);
  }
  return new Uint8Array(buf);
}
function downsampleTo16kAndConvertToPCM16(float32, inRate){
  const outRate=16000;
  if(inRate===outRate) return floatToPCM16Bytes(float32);
  const ratio=inRate/outRate;
  const outLen=Math.round(float32.length/ratio);
  const out=new Float32Array(outLen);
  let oR=0, oB=0;
  while(oR<out.length){
    const nextOB=Math.round((oR+1)*ratio);
    let acc=0,cnt=0;
    for(let i=oB;i<nextOB && i<float32.length;i++){ acc+=float32[i]; cnt++; }
    out[oR]=acc/Math.max(1,cnt);
    oR++; oB=nextOB;
  }
  return floatToPCM16Bytes(out);
}

// ---------- WebSocket ----------
function wsSend(obj){
  if(ws && ws.readyState===WebSocket.OPEN){
    ws.send(JSON.stringify(obj));
  }
}

async function connectWS(){
  const key=ui.apiKey.value.trim();
  if(!key) throw new Error("API Key が空です");
  const url = WS_BASE + "?key=" + encodeURIComponent(key);
  ws = new WebSocket(url);

  /*　↓　2026/02/01 16:56 変更　*/
  /*
  ws.onopen = () => {
    setStatus("good","接続中（setup送信）");
    const model=ui.modelName.value.trim();
    const systemInstruction=ui.systemInstruction.value.trim();

    // ★重要：
    // - 音声は realtimeInput で送る
    // - クール区切りのため VAD を無効化し、ActivityStart/End を自前で送る
    // 仕様: realtimeInput/media_chunks, VAD disabled, ActivityStart/End :contentReference[oaicite:4]{index=4}
    wsSend({
      setup: {
        model,
        generationConfig: {
          responseModalities: ["AUDIO"],
          temperature: 0.4,
          maxOutputTokens: 1024
        },
        inputAudioTranscription: {},
        outputAudioTranscription: {},
        realtimeInputConfig: {
          automaticActivityDetection: { disabled: true }
        },
        ...(systemInstruction ? { systemInstruction } : {})
      }
    });
  };
  */
  /*　↓　2026/02/01 17:55 変更　*/
  /*
  ws.onopen = () => {
    setStatus("good","接続中（setup送信）");
    const model = ui.modelName.value.trim();
  
    const rawSI = ui.systemInstruction.value || "";
    const systemInstruction = sanitizeToUtf8SafeString(rawSI).trim();
  
    const setup = {
      setup: {
        model,
        generationConfig: {
          responseModalities: ["AUDIO"],
          temperature: 0.4,
          maxOutputTokens: 1024
        },
        inputAudioTranscription: {},
        outputAudioTranscription: {},
        // ★ここは入れない（自動VAD有効のまま）
        // realtimeInputConfig: { automaticActivityDetection: { disabled: true } },
        ...(systemInstruction ? { systemInstruction } : {})
      }
    };
  
    console.log("[WS OUT][setup]", setup); // ★要望：console.log
    wsSend(setup);
    console.log("[DEBUG] setup sent, waiting for setupComplete...");
  };
  /*　↑　2026/02/01 16:56 変更　*/

  ws.onopen = () => {
    setStatus("good", "接続中（setup送信）");
  
    const model = ui.modelName.value.trim();
    const rawSI = ui.systemInstruction.value || "";
    const si = sanitizeSystemText(rawSI).trim();
    //const si = sanitizeSystemText(rawSI).trim().slice(0, 4000);
  
    const setup = {
      setup: {
        model,
        generationConfig: {
          responseModalities: ["AUDIO"],
          temperature: 0.4,
          maxOutputTokens: 1024
        },
        inputAudioTranscription: {},
        outputAudioTranscription: {},
        // ★ systemInstruction は Content 型で送る
        ...(si ? {
          systemInstruction: {
            parts: [{ text: si }]
          }
        } : {})
      }
    };
    logOther("[WS OUT][setup] sent", ["setup"]);
    console.log("[WS OUT][setup]", setup);
    console.log("[DEBUG] setup sent, waiting for setupComplete...");
    wsSend(setup);
  };
  /*　↑　2026/02/01 17:55 変更　*/

  ws.onerror = (e) => {
    console.log("[WS ERROR]", e);
    setStatus("bad","WebSocketエラー");
  };

  ws.onclose = (e) => {
    console.log("[WS CLOSE]", { code: e.code, reason: e.reason });
    setStatus("bad","切断: " + (e.reason || ("code="+e.code)));
    if (running) stopSimulation();
  };

  /*　↓　2026/02/01 17:15 変更　*/
  /*
  ws.onmessage = async (ev) => {
    let msg;
    try { msg = JSON.parse(ev.data); } catch { return; }

    // ★要望：常に受信ログ
    console.log("[WS IN]", msg);

    if(msg.setupComplete){
      setupDone = true;
      setStatus("good","接続完了（録音中）");
      return;
    }

    const sc = msg.serverContent || null;

    // inputTranscription / outputTranscription はトップレベルで来ることがある :contentReference[oaicite:5]{index=5}
    const inputT =
      (sc && sc.inputTranscription && sc.inputTranscription.text) ||
      (msg.inputTranscription && msg.inputTranscription.text) || "";

    if (inputT) {
      const t = String(inputT).trim();
      if (t && pendingUserChunks.length > 0) {
        const last = pendingUserChunks[pendingUserChunks.length - 1];
        const bodyEl = last.domEl.querySelector(".text");
        bodyEl.textContent += "\n\n[inputTranscription]\n" + t;
      }
    }

    const outputT =
      (sc && sc.outputTranscription && sc.outputTranscription.text) ||
      (msg.outputTranscription && msg.outputTranscription.text) || "";

    if (outputT) {
      currentAssistantText += String(outputT);
      console.log("[AI OUT +]", String(outputT));
    }

    // AI音声（任意再生）
    if (ui.playAudio.checked && sc && sc.modelTurn && Array.isArray(sc.modelTurn.parts)) {
      for (const part of sc.modelTurn.parts) {
        if (part.inlineData && part.inlineData.data && part.inlineData.mimeType && part.inlineData.mimeType.startsWith("audio/pcm")) {
          try { await playPcm24k(part.inlineData.data); } catch (e) { console.log("[PLAYBACK ERROR]", e); }
        }
      }
    }

    // ターン確定
    if (sc && sc.turnComplete) {
      const out = (currentAssistantText || "").trim();
      if (out) {
        addMessage("ai", out, ["outputTranscription", "turnComplete"]);
        console.log("[AI TURN COMPLETE]", out);
        turnCount++;
        updateCounters();
      } else {
        console.log("[AI TURN COMPLETE] (no transcript text)");
      }
      currentAssistantText = "";
    }
  };
  */

  ws.onmessage = async (ev) => {
    // まず“生”を必ずログ（ここが重要）
    console.log("[WS RAW IN]", ev.data);
  
    let text = null;
  
    try {
      if (typeof ev.data === "string") {
        text = ev.data;
      } else if (ev.data instanceof Blob) {
        text = await ev.data.text();
      } else if (ev.data instanceof ArrayBuffer) {
        text = new TextDecoder("utf-8", { fatal: false }).decode(ev.data);
      } else {
        // 念のため（型が想定外でも落ちないように）
        text = String(ev.data);
      }
    } catch (e) {
      console.log("[WS IN decode error]", e);
      return;
    }
  
    // デコード後のテキストもログ
    console.log("[WS TEXT IN]", text);
  
    // JSONを試す（ダメならそのまま終了）
    let msg;
    try {
      msg = JSON.parse(text);
    } catch (e) {
      console.log("[WS IN not JSON]", e);
      return;
    }
  
    // ここでようやくJSONとしてのログ
    console.log("[WS IN]", msg);
    logOther("[WS IN] " + JSON.stringify(msg), ["ws"]);
  
    // ---- 以降はあなたの既存処理（setupComplete / serverContent etc）をそのまま ----
    if (msg.setupComplete) {
      setupDone = true;
      setStatus("good", "接続完了（録音中）");
      return;
    }
  
    const sc = msg.serverContent || null;
  
    const inputT =
      (sc && sc.inputTranscription && sc.inputTranscription.text) ||
      (msg.inputTranscription && msg.inputTranscription.text) ||
      "";

    /*　↓　2026/02/01 18:15 変更　*/
    /*
    if (inputT) {
      const t = String(inputT).trim();
      if (t && pendingUserChunks.length > 0) {
        const last = pendingUserChunks[pendingUserChunks.length - 1];
        last.domEl.querySelector(".text").textContent += "\n\n[inputTranscription]\n" + t;
      }
    }
    */
    if (inputT) {
      const t = String(inputT).trim();
      if (t) {
        logUser(t, ["inputTranscription"]);
        console.log("[YOU SAID]", t);
      }
    }
    /*　↑　2026/02/01 18:15 変更　*/

  
    const outputT =
      (sc && sc.outputTranscription && sc.outputTranscription.text) ||
      (msg.outputTranscription && msg.outputTranscription.text) ||
      "";
  
    if (outputT) {
      currentAssistantText += String(outputT);
      console.log("[AI OUT +]", String(outputT));
    }

    if (ui.playAudio.checked && sc && sc.modelTurn && Array.isArray(sc.modelTurn.parts)) {
      for (const part of sc.modelTurn.parts) {
        if (part.inlineData && part.inlineData.data && part.inlineData.mimeType && part.inlineData.mimeType.startsWith("audio/pcm")) {
          try { await playPcm24k(part.inlineData.data); } catch (e) { console.log("[PLAYBACK ERROR]", e); }
        }
      }
    }

    /*　↓　2026/02/01 18:15 変更　*/
    /*
    if (sc && sc.turnComplete) {
      const out = (currentAssistantText || "").trim();
      if (out) {
        addMessage("ai", out, ["outputTranscription", "turnComplete"]);
        console.log("[AI TURN COMPLETE]", out);
        turnCount++;
        updateCounters();
      } else {
        console.log("[AI TURN COMPLETE] (no transcript text)");
      }
      currentAssistantText = "";
    }
    */
    // turnComplete時に確定表示
    if (sc && sc.turnComplete) {
      const out = (currentAssistantText || "").trim();
      if (out) {
        logAI(out, ["turnComplete"]);
        console.log("[AI TURN COMPLETE]", out);
        turnCount++;
        updateCounters();
      } else {
        logOther("[AI turnComplete but no transcript text]", ["warn"]);
      }
      currentAssistantText = "";
    }
    /*　↑　2026/02/01 18:15 変更　*/
    
  };
  /*　↑　2026/02/01 17:15 変更　*/

  await new Promise((resolve, reject) => {
    const t = setTimeout(()=>reject(new Error("WS接続タイムアウト")), 8000);
    ws.addEventListener("open", ()=>{ clearTimeout(t); resolve(); }, {once:true});
    ws.addEventListener("error", ()=>{ clearTimeout(t); reject(new Error("WS接続失敗")); }, {once:true});
  });
}

// ---------- AudioWorklet ----------
function makeCaptureWorkletURL(){
  const code = `
  class CaptureProcessor extends AudioWorkletProcessor {
    process(inputs, outputs) {
      const input = inputs[0];
      const output = outputs[0];
      if (input && input[0] && output && output[0]) {
        output[0].set(input[0]);
        const copy = new Float32Array(input[0].length);
        copy.set(input[0]);
        this.port.postMessage(copy.buffer, [copy.buffer]);
      } else if (output && output[0]) {
        output[0].fill(0);
      }
      return true;
    }
  }
  registerProcessor('capture-processor', CaptureProcessor);
  `;
  return URL.createObjectURL(new Blob([code], {type:"application/javascript"}));
}

async function startMic(){
  mediaStream = await navigator.mediaDevices.getUserMedia({
    audio: { channelCount:1, echoCancellation:true, noiseSuppression:true, autoGainControl:true },
    video:false
  });

  audioCtx = new (window.AudioContext || window.webkitAudioContext)();

  const url = makeCaptureWorkletURL();
  await audioCtx.audioWorklet.addModule(url);
  URL.revokeObjectURL(url);

  sourceNode = audioCtx.createMediaStreamSource(mediaStream);

  workletNode = new AudioWorkletNode(audioCtx, "capture-processor", {
    numberOfInputs: 1,
    numberOfOutputs: 1,
    outputChannelCount: [1],
    channelCount: 1
  });

  // keep alive（Chrome対策）
  keepAliveGain = audioCtx.createGain();
  keepAliveGain.gain.value = 0;
  workletNode.connect(keepAliveGain).connect(audioCtx.destination);

  workletNode.port.onmessage = (ev) => {
    if(!running) return;
    const float32 = new Float32Array(ev.data);
    const pcm16 = downsampleTo16kAndConvertToPCM16(float32, audioCtx.sampleRate);
    pcmBytesQueue.push(pcm16);
  };

  sourceNode.connect(workletNode);
}

function stopMic(){
  try{
    if(sourceNode) sourceNode.disconnect();
    if(workletNode) workletNode.disconnect();
    if(keepAliveGain) keepAliveGain.disconnect();
  }catch{}
  sourceNode=null; workletNode=null; keepAliveGain=null;

  if(mediaStream){
    for(const tr of mediaStream.getTracks()) tr.stop();
    mediaStream=null;
  }
  if(audioCtx){
    audioCtx.close().catch(()=>{});
    audioCtx=null;
  }
}

// ---------- RealtimeInput send (per cycle) ----------

/*　↓　2026/02/01 16:57 変更　*/
/*
function flushCycleSendRealtime(){
  if(!ws || ws.readyState!==WebSocket.OPEN) return;
  if(!setupDone) {
    console.log("[SKIP] setup not complete yet");
    return;
  }
  if(pcmBytesQueue.length===0) return;

  const merged = concatUint8(pcmBytesQueue);
  pcmBytesQueue = [];

  const base64 = uint8ToBase64(merged);
  chunkCount++;
  updateCounters();

  const domEl = addMessage("you", `Audio chunk #${chunkCount} 送信（${merged.length} bytes / pcm16@16k / realtimeInput）`, ["realtimeInput","chunk"]);
  pendingUserChunks.push({ id: chunkCount, domEl });

  // ★クール単位で ActivityStart/End を送る（VAD disabled 前提） :contentReference[oaicite:6]{index=6}
  wsSend({ realtimeInput: { activityStart: {} } });
  wsSend({
    realtimeInput: {
      mediaChunks: [
        { mimeType: "audio/pcm;rate=16000", data: base64 }
      ]
    }
  });
  wsSend({ realtimeInput: { activityEnd: {} } });

  console.log("[WS OUT] realtimeInput cycle=", chunkCount, "bytes=", merged.length);
}
*/

function flushCycleSendRealtime(){
  if(!ws || ws.readyState!==WebSocket.OPEN) return;
  if(!setupDone) return; // setupComplete後のみ
  if(pcmBytesQueue.length===0) return;

  const merged = concatUint8(pcmBytesQueue);
  pcmBytesQueue = [];

  const base64 = uint8ToBase64(merged);
  chunkCount++;
  updateCounters();

  /*　↓　2026/02/01 18:36 変更　*/
  /*
  const domEl = addMessage(
    "you",
    `Audio chunk #${chunkCount} 送信（${merged.length} bytes / pcm16@16k / realtimeInput.audio）`,
    ["realtimeInput","audio"]
  );
  pendingUserChunks.push({ id: chunkCount, domEl });
  */
  /*　↑　2026/02/01 18:36 変更　*/

  const payload = {
    realtimeInput: {
      audio: {
        mimeType: "audio/pcm;rate=16000",
        data: base64
      }
    }
  };

  console.log("[WS OUT][realtimeInput.audio]", { chunk: chunkCount, bytes: merged.length });
  logOther(`Sent audio chunk #${chunkCount} (${merged.length} bytes)`, ["audio","out"]);
  wsSend(payload);
}
/*　↑　2026/02/01 16:57 変更　*/

// ---------- optional playback (assume 24k PCM16LE) ----------
async function playPcm24k(base64Pcm){
  const bytes = base64ToUint8(base64Pcm);
  const dv = new DataView(bytes.buffer, bytes.byteOffset, bytes.byteLength);
  const n = bytes.byteLength / 2;
  const float32 = new Float32Array(n);
  for(let i=0;i<n;i++){
    const s = dv.getInt16(i*2, true);
    float32[i] = s / 32768;
  }

  if(!playbackCtx) playbackCtx = new (window.AudioContext || window.webkitAudioContext)();
  const buffer = playbackCtx.createBuffer(1, float32.length, 24000);
  buffer.copyToChannel(float32,0);

  const src = playbackCtx.createBufferSource();
  src.buffer = buffer;
  src.connect(playbackCtx.destination);
  src.start();
}

// ---------- Control ----------
async function startSimulation(){
  if(running) return;
  running = true;

  ui.btnStart.disabled = true;
  ui.btnStop.disabled = false;

  setStatus("", "接続準備中…");

  try{
    await connectWS();
    await startMic();

    const cycle = Math.max(1, Math.min(15, Number(ui.cycleSec.value || 3)));
    cycleTimer = setInterval(flushCycleSendRealtime, cycle*1000);

    logDebug(`<div class="small">
      cycle: <b>${cycle}s</b><br/>
      send: <b>realtimeInput.mediaChunks</b> + <b>ActivityStart/End</b> (VAD disabled)
    </div>`);

    addMessage("ai", "接続しました。話しかけてください。（AI返答は console.log にも常に出ます）", ["system"]);
    updateCounters();
  }catch(err){
    console.log("[START ERROR]", err);
    setStatus("bad", "開始失敗: " + err.message);
    await stopSimulation();
  }
}

async function stopSimulation(){
  running = false;

  ui.btnStart.disabled = false;
  ui.btnStop.disabled = true;

  if(cycleTimer){ clearInterval(cycleTimer); cycleTimer=null; }

  pcmBytesQueue = [];
  setupDone = false;

  stopMic();

  /*　↓　2026/02/01 17:00 追加　*/
  if (ws && ws.readyState === WebSocket.OPEN) {
    const endPayload = { realtimeInput: { audioStreamEnd: true } };
    console.log("[WS OUT][audioStreamEnd]", endPayload);
    wsSend(endPayload);
  }
  /*　↑　2026/02/01 17:00 追加　*/
  
  if(ws){
    try{ ws.close(1000,"user stopped"); }catch{}
    ws=null;
  }

  /*　↓　2026/02/01 18:13 追加　*/
  //clearChat();
  clearAllLogs();
  /*　↑　2026/02/01 18:13 追加　*/

  
  resetStateAll();
}

/*　↓　2026/02/01 16:55 追加　*/
function sanitizeToUtf8SafeString(str) {
  // 不正なサロゲート等を安全化（UTF-8で送れる形に）
  try {
    const enc = new TextEncoder();
    const dec = new TextDecoder("utf-8", { fatal: false });
    return dec.decode(enc.encode(String(str)));
  } catch {
    return String(str);
  }
}
/*　↑　2026/02/01 16:55 追加　*/

/*　↓　2026/02/01 17:54 追加　*/
function sanitizeSystemText(str) {
  const s = String(str ?? "");
  // 孤立サロゲート(UTF-8不正の元)を除去
  return s.replace(/[\uD800-\uDFFF]/g, "");
}
/*　↑　2026/02/01 17:54 追加　*/


ui.btnStart.addEventListener("click", startSimulation);
ui.btnStop.addEventListener("click", stopSimulation);

/*　↓　2026/02/01 18:13 追加　*/
ui.btnClear.addEventListener("click", () => clearAllLogs());
//ui.btnClear.addEventListener("click", () => clearChat());
/*　↑　2026/02/01 18:13 追加　*/

resetStateAll();
</script>
</body>
</html>
